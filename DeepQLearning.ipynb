{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMF+6x7jUy1BB6/ngEWXr13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KillerX629/TPIA/blob/master/DeepQLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8T5dnRf5f58B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "\n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Initialize the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the DQN agent\n",
        "input_size = 1  # replace with your input size\n",
        "hidden_size = 64  # replace with your hidden size\n",
        "num_layers = 2  # replace with your number of layers\n",
        "num_actions = 4  # replace with your number of actions\n",
        "agent = DQN(input_size, hidden_size, num_layers, num_actions).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import namedtuple\n",
        "\n",
        "# Define a namedtuple for a single experience\n",
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "class ReplayBuffer(object):\n",
        "    # This is a simplified version of a replay buffer.\n",
        "    # In a real-world scenario, you might want to add more functionality, such as prioritized experience replay.\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "def optimize_model(agent, memory, optimizer, batch_size, gamma):\n",
        "    if len(memory) < batch_size:\n",
        "        return\n",
        "    transitions = memory.sample(batch_size)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for detailed explanation).\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the columns of actions taken\n",
        "    state_action_values = agent(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    next_state_values = torch.zeros(batch_size, device=device)\n",
        "    next_state_values[non_final_mask] = agent(non_final_next_states).max(1)[0].detach()\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * gamma) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in agent.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "aAthAAB0gQQb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvKPj_x1gnKW",
        "outputId": "9270f07c-f27f-40b6-c585-2f70cc9e2223"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import count\n",
        "import random\n",
        "import math\n",
        "\n",
        "# Initialize the number of steps done\n",
        "steps_done = 0\n",
        "\n",
        "# Set the epsilon start, end, and decay values\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 200\n",
        "\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            return agent(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)"
      ],
      "metadata": {
        "id": "ood8I7yDhk82"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "# Initialize the environment\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "# Initialize the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the DQN agent\n",
        "input_size = env.observation_space.shape[0]\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "num_actions = env.action_space.n\n",
        "agent = DQN(input_size, hidden_size, num_layers, num_actions).to(device)\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer = optim.Adam(agent.parameters())\n",
        "\n",
        "# Initialize the replay buffer\n",
        "memory = ReplayBuffer(10000)\n",
        "\n",
        "# Set the number of episodes\n",
        "num_episodes = 500\n",
        "\n",
        "# Load the model if it exists\n",
        "if os.path.isfile('cartpole_dqn.pt'):\n",
        "    agent.load_state_dict(torch.load('cartpole_dqn.pt'))\n",
        "\n",
        "# Training loop\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and get it's state\n",
        "    state, info = env.reset()\n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(0)\n",
        "    for t in count():\n",
        "        # Select and perform an action\n",
        "        action = select_action(state)\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "\n",
        "        if terminated or truncated:\n",
        "            next_state = None\n",
        "        else:\n",
        "            next_state = torch.tensor(next_state, dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the target network)\n",
        "        optimize_model(agent, memory, optimizer, 128, 0.999)\n",
        "\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    # Save the model\n",
        "    torch.save(agent.state_dict(), 'cartpole_dqn.pt')\n",
        "\n",
        "    # Print the episode number and the number of timesteps\n",
        "    print(f\"Episode {i_episode + 1}/{num_episodes}, Timesteps: {t + 1}\")\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mIlZ1EVgUqe",
        "outputId": "47b30b44-7d2a-40ad-af3a-e0371ae6687c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1/500, Timesteps: 20\n",
            "Episode 2/500, Timesteps: 30\n",
            "Episode 3/500, Timesteps: 13\n",
            "Episode 4/500, Timesteps: 13\n",
            "Episode 5/500, Timesteps: 10\n",
            "Episode 6/500, Timesteps: 14\n",
            "Episode 7/500, Timesteps: 18\n",
            "Episode 8/500, Timesteps: 9\n",
            "Episode 9/500, Timesteps: 13\n",
            "Episode 10/500, Timesteps: 10\n",
            "Episode 11/500, Timesteps: 14\n",
            "Episode 12/500, Timesteps: 13\n",
            "Episode 13/500, Timesteps: 12\n",
            "Episode 14/500, Timesteps: 10\n",
            "Episode 15/500, Timesteps: 10\n",
            "Episode 16/500, Timesteps: 14\n",
            "Episode 17/500, Timesteps: 12\n",
            "Episode 18/500, Timesteps: 13\n",
            "Episode 19/500, Timesteps: 10\n",
            "Episode 20/500, Timesteps: 9\n",
            "Episode 21/500, Timesteps: 12\n",
            "Episode 22/500, Timesteps: 8\n",
            "Episode 23/500, Timesteps: 14\n",
            "Episode 24/500, Timesteps: 10\n",
            "Episode 25/500, Timesteps: 8\n",
            "Episode 26/500, Timesteps: 22\n",
            "Episode 27/500, Timesteps: 10\n",
            "Episode 28/500, Timesteps: 11\n",
            "Episode 29/500, Timesteps: 11\n",
            "Episode 30/500, Timesteps: 10\n",
            "Episode 31/500, Timesteps: 11\n",
            "Episode 32/500, Timesteps: 9\n",
            "Episode 33/500, Timesteps: 11\n",
            "Episode 34/500, Timesteps: 9\n",
            "Episode 35/500, Timesteps: 10\n",
            "Episode 36/500, Timesteps: 12\n",
            "Episode 37/500, Timesteps: 10\n",
            "Episode 38/500, Timesteps: 14\n",
            "Episode 39/500, Timesteps: 9\n",
            "Episode 40/500, Timesteps: 11\n",
            "Episode 41/500, Timesteps: 11\n",
            "Episode 42/500, Timesteps: 8\n",
            "Episode 43/500, Timesteps: 10\n",
            "Episode 44/500, Timesteps: 9\n",
            "Episode 45/500, Timesteps: 10\n",
            "Episode 46/500, Timesteps: 11\n",
            "Episode 47/500, Timesteps: 9\n",
            "Episode 48/500, Timesteps: 9\n",
            "Episode 49/500, Timesteps: 10\n",
            "Episode 50/500, Timesteps: 9\n",
            "Episode 51/500, Timesteps: 9\n",
            "Episode 52/500, Timesteps: 10\n",
            "Episode 53/500, Timesteps: 9\n",
            "Episode 54/500, Timesteps: 10\n",
            "Episode 55/500, Timesteps: 8\n",
            "Episode 56/500, Timesteps: 10\n",
            "Episode 57/500, Timesteps: 9\n",
            "Episode 58/500, Timesteps: 9\n",
            "Episode 59/500, Timesteps: 10\n",
            "Episode 60/500, Timesteps: 9\n",
            "Episode 61/500, Timesteps: 11\n",
            "Episode 62/500, Timesteps: 13\n",
            "Episode 63/500, Timesteps: 9\n",
            "Episode 64/500, Timesteps: 10\n",
            "Episode 65/500, Timesteps: 11\n",
            "Episode 66/500, Timesteps: 9\n",
            "Episode 67/500, Timesteps: 11\n",
            "Episode 68/500, Timesteps: 9\n",
            "Episode 69/500, Timesteps: 9\n",
            "Episode 70/500, Timesteps: 10\n",
            "Episode 71/500, Timesteps: 10\n",
            "Episode 72/500, Timesteps: 9\n",
            "Episode 73/500, Timesteps: 8\n",
            "Episode 74/500, Timesteps: 9\n",
            "Episode 75/500, Timesteps: 8\n",
            "Episode 76/500, Timesteps: 9\n",
            "Episode 77/500, Timesteps: 10\n",
            "Episode 78/500, Timesteps: 11\n",
            "Episode 79/500, Timesteps: 9\n",
            "Episode 80/500, Timesteps: 9\n",
            "Episode 81/500, Timesteps: 10\n",
            "Episode 82/500, Timesteps: 8\n",
            "Episode 83/500, Timesteps: 10\n",
            "Episode 84/500, Timesteps: 9\n",
            "Episode 85/500, Timesteps: 11\n",
            "Episode 86/500, Timesteps: 9\n",
            "Episode 87/500, Timesteps: 12\n",
            "Episode 88/500, Timesteps: 10\n",
            "Episode 89/500, Timesteps: 10\n",
            "Episode 90/500, Timesteps: 9\n",
            "Episode 91/500, Timesteps: 8\n",
            "Episode 92/500, Timesteps: 10\n",
            "Episode 93/500, Timesteps: 10\n",
            "Episode 94/500, Timesteps: 8\n",
            "Episode 95/500, Timesteps: 11\n",
            "Episode 96/500, Timesteps: 8\n",
            "Episode 97/500, Timesteps: 10\n",
            "Episode 98/500, Timesteps: 10\n",
            "Episode 99/500, Timesteps: 9\n",
            "Episode 100/500, Timesteps: 9\n",
            "Episode 101/500, Timesteps: 10\n",
            "Episode 102/500, Timesteps: 11\n",
            "Episode 103/500, Timesteps: 9\n",
            "Episode 104/500, Timesteps: 9\n",
            "Episode 105/500, Timesteps: 10\n",
            "Episode 106/500, Timesteps: 9\n",
            "Episode 107/500, Timesteps: 9\n",
            "Episode 108/500, Timesteps: 10\n",
            "Episode 109/500, Timesteps: 10\n",
            "Episode 110/500, Timesteps: 10\n",
            "Episode 111/500, Timesteps: 10\n",
            "Episode 112/500, Timesteps: 9\n",
            "Episode 113/500, Timesteps: 10\n",
            "Episode 114/500, Timesteps: 10\n",
            "Episode 115/500, Timesteps: 10\n",
            "Episode 116/500, Timesteps: 9\n",
            "Episode 117/500, Timesteps: 8\n",
            "Episode 118/500, Timesteps: 10\n",
            "Episode 119/500, Timesteps: 8\n",
            "Episode 120/500, Timesteps: 10\n",
            "Episode 121/500, Timesteps: 10\n",
            "Episode 122/500, Timesteps: 10\n",
            "Episode 123/500, Timesteps: 12\n",
            "Episode 124/500, Timesteps: 8\n",
            "Episode 125/500, Timesteps: 11\n",
            "Episode 126/500, Timesteps: 10\n",
            "Episode 127/500, Timesteps: 10\n",
            "Episode 128/500, Timesteps: 10\n",
            "Episode 129/500, Timesteps: 9\n",
            "Episode 130/500, Timesteps: 10\n",
            "Episode 131/500, Timesteps: 10\n",
            "Episode 132/500, Timesteps: 11\n",
            "Episode 133/500, Timesteps: 9\n",
            "Episode 134/500, Timesteps: 9\n",
            "Episode 135/500, Timesteps: 8\n",
            "Episode 136/500, Timesteps: 10\n",
            "Episode 137/500, Timesteps: 9\n",
            "Episode 138/500, Timesteps: 10\n",
            "Episode 139/500, Timesteps: 10\n",
            "Episode 140/500, Timesteps: 10\n",
            "Episode 141/500, Timesteps: 9\n",
            "Episode 142/500, Timesteps: 9\n",
            "Episode 143/500, Timesteps: 10\n",
            "Episode 144/500, Timesteps: 8\n",
            "Episode 145/500, Timesteps: 9\n",
            "Episode 146/500, Timesteps: 9\n",
            "Episode 147/500, Timesteps: 10\n",
            "Episode 148/500, Timesteps: 10\n",
            "Episode 149/500, Timesteps: 12\n",
            "Episode 150/500, Timesteps: 9\n",
            "Episode 151/500, Timesteps: 10\n",
            "Episode 152/500, Timesteps: 8\n",
            "Episode 153/500, Timesteps: 9\n",
            "Episode 154/500, Timesteps: 9\n",
            "Episode 155/500, Timesteps: 8\n",
            "Episode 156/500, Timesteps: 10\n",
            "Episode 157/500, Timesteps: 9\n",
            "Episode 158/500, Timesteps: 10\n",
            "Episode 159/500, Timesteps: 10\n",
            "Episode 160/500, Timesteps: 10\n",
            "Episode 161/500, Timesteps: 10\n",
            "Episode 162/500, Timesteps: 10\n",
            "Episode 163/500, Timesteps: 10\n",
            "Episode 164/500, Timesteps: 9\n",
            "Episode 165/500, Timesteps: 9\n",
            "Episode 166/500, Timesteps: 10\n",
            "Episode 167/500, Timesteps: 8\n",
            "Episode 168/500, Timesteps: 11\n",
            "Episode 169/500, Timesteps: 11\n",
            "Episode 170/500, Timesteps: 10\n",
            "Episode 171/500, Timesteps: 9\n",
            "Episode 172/500, Timesteps: 9\n",
            "Episode 173/500, Timesteps: 10\n",
            "Episode 174/500, Timesteps: 10\n",
            "Episode 175/500, Timesteps: 9\n",
            "Episode 176/500, Timesteps: 9\n",
            "Episode 177/500, Timesteps: 9\n",
            "Episode 178/500, Timesteps: 11\n",
            "Episode 179/500, Timesteps: 10\n",
            "Episode 180/500, Timesteps: 12\n",
            "Episode 181/500, Timesteps: 10\n",
            "Episode 182/500, Timesteps: 10\n",
            "Episode 183/500, Timesteps: 10\n",
            "Episode 184/500, Timesteps: 8\n",
            "Episode 185/500, Timesteps: 10\n",
            "Episode 186/500, Timesteps: 10\n",
            "Episode 187/500, Timesteps: 10\n",
            "Episode 188/500, Timesteps: 9\n",
            "Episode 189/500, Timesteps: 9\n",
            "Episode 190/500, Timesteps: 10\n",
            "Episode 191/500, Timesteps: 8\n",
            "Episode 192/500, Timesteps: 10\n",
            "Episode 193/500, Timesteps: 9\n",
            "Episode 194/500, Timesteps: 10\n",
            "Episode 195/500, Timesteps: 9\n",
            "Episode 196/500, Timesteps: 9\n",
            "Episode 197/500, Timesteps: 10\n",
            "Episode 198/500, Timesteps: 9\n",
            "Episode 199/500, Timesteps: 9\n",
            "Episode 200/500, Timesteps: 9\n",
            "Episode 201/500, Timesteps: 9\n",
            "Episode 202/500, Timesteps: 9\n",
            "Episode 203/500, Timesteps: 9\n",
            "Episode 204/500, Timesteps: 10\n",
            "Episode 205/500, Timesteps: 9\n",
            "Episode 206/500, Timesteps: 8\n",
            "Episode 207/500, Timesteps: 10\n",
            "Episode 208/500, Timesteps: 9\n",
            "Episode 209/500, Timesteps: 8\n",
            "Episode 210/500, Timesteps: 10\n",
            "Episode 211/500, Timesteps: 10\n",
            "Episode 212/500, Timesteps: 11\n",
            "Episode 213/500, Timesteps: 10\n",
            "Episode 214/500, Timesteps: 10\n",
            "Episode 215/500, Timesteps: 10\n",
            "Episode 216/500, Timesteps: 10\n",
            "Episode 217/500, Timesteps: 10\n",
            "Episode 218/500, Timesteps: 9\n",
            "Episode 219/500, Timesteps: 10\n",
            "Episode 220/500, Timesteps: 9\n",
            "Episode 221/500, Timesteps: 9\n",
            "Episode 222/500, Timesteps: 10\n",
            "Episode 223/500, Timesteps: 9\n",
            "Episode 224/500, Timesteps: 9\n",
            "Episode 225/500, Timesteps: 10\n",
            "Episode 226/500, Timesteps: 9\n",
            "Episode 227/500, Timesteps: 8\n",
            "Episode 228/500, Timesteps: 14\n",
            "Episode 229/500, Timesteps: 8\n",
            "Episode 230/500, Timesteps: 9\n",
            "Episode 231/500, Timesteps: 10\n",
            "Episode 232/500, Timesteps: 10\n",
            "Episode 233/500, Timesteps: 9\n",
            "Episode 234/500, Timesteps: 9\n",
            "Episode 235/500, Timesteps: 10\n",
            "Episode 236/500, Timesteps: 8\n",
            "Episode 237/500, Timesteps: 10\n",
            "Episode 238/500, Timesteps: 8\n",
            "Episode 239/500, Timesteps: 10\n",
            "Episode 240/500, Timesteps: 8\n",
            "Episode 241/500, Timesteps: 8\n",
            "Episode 242/500, Timesteps: 10\n",
            "Episode 243/500, Timesteps: 8\n",
            "Episode 244/500, Timesteps: 10\n",
            "Episode 245/500, Timesteps: 9\n",
            "Episode 246/500, Timesteps: 9\n",
            "Episode 247/500, Timesteps: 10\n",
            "Episode 248/500, Timesteps: 11\n",
            "Episode 249/500, Timesteps: 9\n",
            "Episode 250/500, Timesteps: 9\n",
            "Episode 251/500, Timesteps: 11\n",
            "Episode 252/500, Timesteps: 9\n",
            "Episode 253/500, Timesteps: 11\n",
            "Episode 254/500, Timesteps: 10\n",
            "Episode 255/500, Timesteps: 11\n",
            "Episode 256/500, Timesteps: 9\n",
            "Episode 257/500, Timesteps: 10\n",
            "Episode 258/500, Timesteps: 10\n",
            "Episode 259/500, Timesteps: 10\n",
            "Episode 260/500, Timesteps: 10\n",
            "Episode 261/500, Timesteps: 13\n",
            "Episode 262/500, Timesteps: 10\n",
            "Episode 263/500, Timesteps: 11\n",
            "Episode 264/500, Timesteps: 9\n",
            "Episode 265/500, Timesteps: 9\n",
            "Episode 266/500, Timesteps: 9\n",
            "Episode 267/500, Timesteps: 9\n",
            "Episode 268/500, Timesteps: 8\n",
            "Episode 269/500, Timesteps: 10\n",
            "Episode 270/500, Timesteps: 9\n",
            "Episode 271/500, Timesteps: 10\n",
            "Episode 272/500, Timesteps: 9\n",
            "Episode 273/500, Timesteps: 8\n",
            "Episode 274/500, Timesteps: 10\n",
            "Episode 275/500, Timesteps: 10\n",
            "Episode 276/500, Timesteps: 8\n",
            "Episode 277/500, Timesteps: 9\n",
            "Episode 278/500, Timesteps: 8\n",
            "Episode 279/500, Timesteps: 9\n",
            "Episode 280/500, Timesteps: 9\n",
            "Episode 281/500, Timesteps: 10\n",
            "Episode 282/500, Timesteps: 10\n",
            "Episode 283/500, Timesteps: 8\n",
            "Episode 284/500, Timesteps: 10\n",
            "Episode 285/500, Timesteps: 8\n",
            "Episode 286/500, Timesteps: 8\n",
            "Episode 287/500, Timesteps: 10\n",
            "Episode 288/500, Timesteps: 9\n",
            "Episode 289/500, Timesteps: 10\n",
            "Episode 290/500, Timesteps: 10\n",
            "Episode 291/500, Timesteps: 8\n",
            "Episode 292/500, Timesteps: 9\n",
            "Episode 293/500, Timesteps: 9\n",
            "Episode 294/500, Timesteps: 9\n",
            "Episode 295/500, Timesteps: 10\n",
            "Episode 296/500, Timesteps: 9\n",
            "Episode 297/500, Timesteps: 9\n",
            "Episode 298/500, Timesteps: 9\n",
            "Episode 299/500, Timesteps: 10\n",
            "Episode 300/500, Timesteps: 9\n",
            "Episode 301/500, Timesteps: 9\n",
            "Episode 302/500, Timesteps: 10\n",
            "Episode 303/500, Timesteps: 9\n",
            "Episode 304/500, Timesteps: 10\n",
            "Episode 305/500, Timesteps: 10\n",
            "Episode 306/500, Timesteps: 10\n",
            "Episode 307/500, Timesteps: 9\n",
            "Episode 308/500, Timesteps: 8\n",
            "Episode 309/500, Timesteps: 9\n",
            "Episode 310/500, Timesteps: 9\n",
            "Episode 311/500, Timesteps: 9\n",
            "Episode 312/500, Timesteps: 9\n",
            "Episode 313/500, Timesteps: 9\n",
            "Episode 314/500, Timesteps: 11\n",
            "Episode 315/500, Timesteps: 10\n",
            "Episode 316/500, Timesteps: 9\n",
            "Episode 317/500, Timesteps: 10\n",
            "Episode 318/500, Timesteps: 10\n",
            "Episode 319/500, Timesteps: 12\n",
            "Episode 320/500, Timesteps: 10\n",
            "Episode 321/500, Timesteps: 8\n",
            "Episode 322/500, Timesteps: 8\n",
            "Episode 323/500, Timesteps: 9\n",
            "Episode 324/500, Timesteps: 11\n",
            "Episode 325/500, Timesteps: 10\n",
            "Episode 326/500, Timesteps: 8\n",
            "Episode 327/500, Timesteps: 9\n",
            "Episode 328/500, Timesteps: 10\n",
            "Episode 329/500, Timesteps: 10\n",
            "Episode 330/500, Timesteps: 9\n",
            "Episode 331/500, Timesteps: 9\n",
            "Episode 332/500, Timesteps: 9\n",
            "Episode 333/500, Timesteps: 10\n",
            "Episode 334/500, Timesteps: 11\n",
            "Episode 335/500, Timesteps: 10\n",
            "Episode 336/500, Timesteps: 8\n",
            "Episode 337/500, Timesteps: 10\n",
            "Episode 338/500, Timesteps: 9\n",
            "Episode 339/500, Timesteps: 10\n",
            "Episode 340/500, Timesteps: 8\n",
            "Episode 341/500, Timesteps: 10\n",
            "Episode 342/500, Timesteps: 10\n",
            "Episode 343/500, Timesteps: 9\n",
            "Episode 344/500, Timesteps: 12\n",
            "Episode 345/500, Timesteps: 12\n",
            "Episode 346/500, Timesteps: 10\n",
            "Episode 347/500, Timesteps: 8\n",
            "Episode 348/500, Timesteps: 10\n",
            "Episode 349/500, Timesteps: 10\n",
            "Episode 350/500, Timesteps: 10\n",
            "Episode 351/500, Timesteps: 8\n",
            "Episode 352/500, Timesteps: 8\n",
            "Episode 353/500, Timesteps: 9\n",
            "Episode 354/500, Timesteps: 10\n",
            "Episode 355/500, Timesteps: 11\n",
            "Episode 356/500, Timesteps: 10\n",
            "Episode 357/500, Timesteps: 11\n",
            "Episode 358/500, Timesteps: 10\n",
            "Episode 359/500, Timesteps: 12\n",
            "Episode 360/500, Timesteps: 10\n",
            "Episode 361/500, Timesteps: 11\n",
            "Episode 362/500, Timesteps: 11\n",
            "Episode 363/500, Timesteps: 8\n",
            "Episode 364/500, Timesteps: 10\n",
            "Episode 365/500, Timesteps: 10\n",
            "Episode 366/500, Timesteps: 9\n",
            "Episode 367/500, Timesteps: 9\n",
            "Episode 368/500, Timesteps: 11\n",
            "Episode 369/500, Timesteps: 10\n",
            "Episode 370/500, Timesteps: 9\n",
            "Episode 371/500, Timesteps: 9\n",
            "Episode 372/500, Timesteps: 8\n",
            "Episode 373/500, Timesteps: 9\n",
            "Episode 374/500, Timesteps: 8\n",
            "Episode 375/500, Timesteps: 8\n",
            "Episode 376/500, Timesteps: 9\n",
            "Episode 377/500, Timesteps: 11\n",
            "Episode 378/500, Timesteps: 9\n",
            "Episode 379/500, Timesteps: 9\n",
            "Episode 380/500, Timesteps: 9\n",
            "Episode 381/500, Timesteps: 9\n",
            "Episode 382/500, Timesteps: 10\n",
            "Episode 383/500, Timesteps: 8\n",
            "Episode 384/500, Timesteps: 11\n",
            "Episode 385/500, Timesteps: 9\n",
            "Episode 386/500, Timesteps: 9\n",
            "Episode 387/500, Timesteps: 8\n",
            "Episode 388/500, Timesteps: 10\n",
            "Episode 389/500, Timesteps: 11\n",
            "Episode 390/500, Timesteps: 12\n",
            "Episode 391/500, Timesteps: 10\n",
            "Episode 392/500, Timesteps: 8\n",
            "Episode 393/500, Timesteps: 10\n",
            "Episode 394/500, Timesteps: 10\n",
            "Episode 395/500, Timesteps: 10\n",
            "Episode 396/500, Timesteps: 9\n",
            "Episode 397/500, Timesteps: 10\n",
            "Episode 398/500, Timesteps: 11\n",
            "Episode 399/500, Timesteps: 10\n",
            "Episode 400/500, Timesteps: 12\n",
            "Episode 401/500, Timesteps: 8\n",
            "Episode 402/500, Timesteps: 9\n",
            "Episode 403/500, Timesteps: 8\n",
            "Episode 404/500, Timesteps: 11\n",
            "Episode 405/500, Timesteps: 9\n",
            "Episode 406/500, Timesteps: 9\n",
            "Episode 407/500, Timesteps: 10\n",
            "Episode 408/500, Timesteps: 10\n",
            "Episode 409/500, Timesteps: 8\n",
            "Episode 410/500, Timesteps: 8\n",
            "Episode 411/500, Timesteps: 10\n",
            "Episode 412/500, Timesteps: 9\n",
            "Episode 413/500, Timesteps: 10\n",
            "Episode 414/500, Timesteps: 9\n",
            "Episode 415/500, Timesteps: 12\n",
            "Episode 416/500, Timesteps: 9\n",
            "Episode 417/500, Timesteps: 9\n",
            "Episode 418/500, Timesteps: 10\n",
            "Episode 419/500, Timesteps: 9\n",
            "Episode 420/500, Timesteps: 10\n",
            "Episode 421/500, Timesteps: 10\n",
            "Episode 422/500, Timesteps: 10\n",
            "Episode 423/500, Timesteps: 10\n",
            "Episode 424/500, Timesteps: 9\n",
            "Episode 425/500, Timesteps: 8\n",
            "Episode 426/500, Timesteps: 9\n",
            "Episode 427/500, Timesteps: 10\n",
            "Episode 428/500, Timesteps: 10\n",
            "Episode 429/500, Timesteps: 9\n",
            "Episode 430/500, Timesteps: 10\n",
            "Episode 431/500, Timesteps: 9\n",
            "Episode 432/500, Timesteps: 10\n",
            "Episode 433/500, Timesteps: 10\n",
            "Episode 434/500, Timesteps: 8\n",
            "Episode 435/500, Timesteps: 9\n",
            "Episode 436/500, Timesteps: 10\n",
            "Episode 437/500, Timesteps: 10\n",
            "Episode 438/500, Timesteps: 12\n",
            "Episode 439/500, Timesteps: 9\n",
            "Episode 440/500, Timesteps: 10\n",
            "Episode 441/500, Timesteps: 10\n",
            "Episode 442/500, Timesteps: 9\n",
            "Episode 443/500, Timesteps: 10\n",
            "Episode 444/500, Timesteps: 11\n",
            "Episode 445/500, Timesteps: 10\n",
            "Episode 446/500, Timesteps: 10\n",
            "Episode 447/500, Timesteps: 10\n",
            "Episode 448/500, Timesteps: 12\n",
            "Episode 449/500, Timesteps: 10\n",
            "Episode 450/500, Timesteps: 10\n",
            "Episode 451/500, Timesteps: 9\n",
            "Episode 452/500, Timesteps: 10\n",
            "Episode 453/500, Timesteps: 10\n",
            "Episode 454/500, Timesteps: 10\n",
            "Episode 455/500, Timesteps: 9\n",
            "Episode 456/500, Timesteps: 9\n",
            "Episode 457/500, Timesteps: 8\n",
            "Episode 458/500, Timesteps: 9\n",
            "Episode 459/500, Timesteps: 9\n",
            "Episode 460/500, Timesteps: 9\n",
            "Episode 461/500, Timesteps: 11\n",
            "Episode 462/500, Timesteps: 10\n",
            "Episode 463/500, Timesteps: 9\n",
            "Episode 464/500, Timesteps: 9\n",
            "Episode 465/500, Timesteps: 10\n",
            "Episode 466/500, Timesteps: 9\n",
            "Episode 467/500, Timesteps: 10\n",
            "Episode 468/500, Timesteps: 9\n",
            "Episode 469/500, Timesteps: 9\n",
            "Episode 470/500, Timesteps: 9\n",
            "Episode 471/500, Timesteps: 9\n",
            "Episode 472/500, Timesteps: 8\n",
            "Episode 473/500, Timesteps: 9\n",
            "Episode 474/500, Timesteps: 10\n",
            "Episode 475/500, Timesteps: 10\n",
            "Episode 476/500, Timesteps: 9\n",
            "Episode 477/500, Timesteps: 10\n",
            "Episode 478/500, Timesteps: 10\n",
            "Episode 479/500, Timesteps: 10\n",
            "Episode 480/500, Timesteps: 10\n",
            "Episode 481/500, Timesteps: 11\n",
            "Episode 482/500, Timesteps: 9\n",
            "Episode 483/500, Timesteps: 10\n",
            "Episode 484/500, Timesteps: 8\n",
            "Episode 485/500, Timesteps: 10\n",
            "Episode 486/500, Timesteps: 10\n",
            "Episode 487/500, Timesteps: 10\n",
            "Episode 488/500, Timesteps: 11\n",
            "Episode 489/500, Timesteps: 9\n",
            "Episode 490/500, Timesteps: 10\n",
            "Episode 491/500, Timesteps: 9\n",
            "Episode 492/500, Timesteps: 9\n",
            "Episode 493/500, Timesteps: 11\n",
            "Episode 494/500, Timesteps: 10\n",
            "Episode 495/500, Timesteps: 9\n",
            "Episode 496/500, Timesteps: 9\n",
            "Episode 497/500, Timesteps: 9\n",
            "Episode 498/500, Timesteps: 9\n",
            "Episode 499/500, Timesteps: 11\n",
            "Episode 500/500, Timesteps: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yUGgb7MShF3w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}